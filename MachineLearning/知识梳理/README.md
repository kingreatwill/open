[TOC]

# ç»Ÿè®¡å­¦ä¹ æ–¹æ³•

[ç¬¬ä¸€ç‰ˆ](https://github.com/kingreatwill/files/tree/main/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/book/Lihang-first_edition)

[ç¬¬äºŒç‰ˆ](https://github.com/kingreatwill/files/tree/main/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/book/Lihang-second_edition)

## ç¬¬ 1 ç«  ç»Ÿè®¡å­¦ä¹ åŠç›‘ç£å­¦ä¹ æ¦‚è®º

**ç»Ÿè®¡å­¦ä¹ çš„ä¸»è¦ç‰¹ç‚¹æ˜¯**ï¼š

1. ç»Ÿè®¡å­¦ä¹ ä»¥è®¡ç®—æœºåŠç½‘ç»œä¸ºå¹³å°ï¼Œæ˜¯å»ºç«‹åœ¨è®¡ç®—æœºåŠç½‘ç»œä¹‹ä¸Šçš„ï¼›
2. ç»Ÿè®¡å­¦ä¹ ä»¥æ•°æ®ä¸ºç ”ç©¶å¯¹è±¡ï¼Œæ˜¯æ•°æ®é©±åŠ¨çš„å­¦ç§‘ï¼›
3. ç»Ÿè®¡å­¦ä¹ çš„ç›®çš„æ˜¯å¯¹æ•°æ®è¿›è¡Œé¢„æµ‹ä¸åˆ†æï¼›
4. ç»Ÿè®¡å­¦ä¹ ä»¥æ–¹æ³•ä¸ºä¸­å¿ƒï¼Œç»Ÿè®¡å­¦ä¹ æ–¹æ³•æ„å»ºæ¨¡å‹å¹¶åº”ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ä¸åˆ†æï¼›
5. ç»Ÿè®¡å­¦ä¹ æ˜¯æ¦‚ç‡è®ºã€ç»Ÿè®¡å­¦ã€ä¿¡æ¯è®ºã€è®¡ç®—ç†è®ºã€æœ€ä¼˜åŒ–ç†è®ºåŠè®¡ç®—æœºç§‘å­¦ç­‰å¤šä¸ªé¢†åŸŸçš„äº¤å‰å­¦ç§‘ï¼Œå¹¶ä¸”åœ¨å‘å±•ä¸­é€æ­¥å½¢æˆç‹¬è‡ªçš„ç†è®ºä½“ç³»ä¸æ–¹æ³•è®ºã€‚

**å‡è®¾ç©ºé—´(hypothesis space)**ï¼š
$$\mathcal H = \{ f(x;\theta) | \theta \in \mathbb{R}^D\} \\ or \quad \mathcal F = \{P|P(Y|X;\theta),\theta \in \mathbb{R}^D\}$$
å…¶ä¸­$f(x; \theta)$æ˜¯å‚æ•°ä¸º$\theta$ çš„å‡½æ•°ï¼ˆ**å†³ç­–å‡½æ•°**ï¼‰ï¼Œä¹Ÿç§°ä¸ºæ¨¡å‹ï¼ˆModelï¼‰ï¼Œå‚æ•°å‘é‡$\theta$å–å€¼ä¸$D$ç»´æ¬§å¼ç©ºé—´$\mathbb{R}^D$,ä¹Ÿç§°ä¸ºå‚æ•°ç©ºé—´(parameter space)ï¼Œ$D$ ä¸ºå‚æ•°çš„æ•°é‡(ç»´åº¦)

æ¨¡å‹çš„å‡è®¾ç©ºé—´(hypothesis space)åŒ…å«æ‰€æœ‰å¯èƒ½çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒæˆ–å†³ç­–å‡½æ•°

**ç‰¹å¾ç©ºé—´ï¼ˆfeature spaceï¼‰**ï¼š
æ¯ä¸ªå…·ä½“çš„è¾“å…¥æ˜¯ä¸€ä¸ªå®ä¾‹ï¼ˆinstanceï¼‰ï¼Œé€šå¸¸ç”±ç‰¹å¾å‘é‡ï¼ˆfeature vectorï¼‰è¡¨ç¤ºã€‚è¿™
æ—¶ï¼Œæ‰€æœ‰ç‰¹å¾å‘é‡å­˜åœ¨çš„ç©ºé—´ç§°ä¸ºç‰¹å¾ç©ºé—´ï¼ˆfeature spaceï¼‰ã€‚ç‰¹å¾ç©ºé—´çš„æ¯ä¸€ç»´å¯¹åº”äº
ä¸€ä¸ªç‰¹å¾ã€‚

> è¾“å…¥ç©ºé—´ä¸­çš„ä¸€ä¸ªè¾“å…¥å‘é‡$x = (x_1,x_2)$ï¼Œåœ¨å¤šé¡¹å¼æ¨¡å‹ä¸­ç‰¹å¾å‘é‡æ˜¯($x_1^2,x_1x_2,x_2^2,...$)
> ä¸€èˆ¬è¯´çš„çº¿æ€§æ¨¡å‹ï¼ŒæŒ‡çš„æ˜¯ç‰¹å¾å‘é‡çš„çº¿æ€§ç»„åˆï¼Œè€Œä¸æ˜¯æŒ‡è¾“å…¥å‘é‡ï¼Œæ‰€ä»¥è¯´æ¨¡å‹éƒ½æ˜¯å®šä¹‰åœ¨ç‰¹å¾ç©ºé—´ä¸Šçš„

**ç»Ÿè®¡å­¦ä¹ çš„ä¸‰è¦ç´ **ï¼š

1. æ¨¡å‹çš„å‡è®¾ç©ºé—´(hypothesis space)ï¼Œç®€ç§°ï¼šæ¨¡å‹(model)
2. æ¨¡å‹é€‰æ‹©çš„å‡†åˆ™(evaluation criterion)ï¼Œç®€ç§°ï¼šç­–ç•¥(strategy)æˆ–è€…å­¦ä¹ å‡†åˆ™
3. æ¨¡å‹å­¦ä¹ çš„ç®—æ³•(algorithm)ï¼Œç®€ç§°ï¼šç®—æ³•(algorithm)

> ä»¥çº¿æ€§å›å½’ï¼ˆLinear Regressionï¼‰ä¸ºä¾‹ï¼š
> æ¨¡å‹ï¼š $f(x;w,b) = w^Tx +b$
> ç­–ç•¥(strategy)æˆ–è€…å­¦ä¹ å‡†åˆ™: å¹³æ–¹æŸå¤±å‡½æ•° $\mathcal L(y,\hat{y}) = (y-f(x,\theta))^2$
> ç®—æ³•ï¼šè§£æè§£analytical solution(é—­å¼è§£closed-form solution)å’Œæ•°å€¼è§£numerical solutionï¼Œå¦‚ï¼šclosed-formçš„æœ€å°äºŒä¹˜çš„è§£ä»¥åŠæ¢¯åº¦ä¸‹é™æ³•

**æœºå™¨å­¦ä¹ çš„å®šä¹‰**ï¼š

```mermaid
graph LR;
    F(["æœªçŸ¥çš„ç›®æ ‡å‡½æ•°(ç†æƒ³ä¸­å®Œç¾çš„å‡½æ•°)ï¼šğ‘“: ğ’™âŸ¶ğ‘¦"])-->D["è®­ç»ƒæ ·æœ¬D:{(ğ’™Â¹,ğ‘¦Â¹),...,(ğ’™â¿,ğ‘¦â¿)}"];
    D-->A{{"ç®—æ³•"}}
    H{{"å‡è®¾ç©ºé—´"}}-->A
    A-->G["æ¨¡å‹ gâ‰ˆf"]
```

ä½¿ç”¨è®­ç»ƒæ•°æ®æ¥è®¡ç®—æ¥è¿‘ç›®æ ‡ ğ‘“ çš„å‡è®¾ï¼ˆhypothesis ï¼‰g ï¼ˆæ¥è‡ªï¼š[Machine Learning Foundationsï¼ˆæœºå™¨å­¦ä¹ åŸºçŸ³ï¼‰,25 é¡µ](https://www.csie.ntu.edu.tw/~htlin/course/mlfound17fall/doc/01_handout.pdf)ï¼‰


**ç›‘ç£å­¦ä¹ **ï¼š
ç›‘ç£å­¦ä¹ (supervised learning)æ˜¯æŒ‡ä»æ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ é¢„æµ‹æ¨¡å‹çš„æœºå™¨å­¦ä¹ é—®é¢˜ã€‚æœ¬è´¨æ˜¯**å­¦ä¹ è¾“å…¥åˆ°è¾“å‡ºçš„æ˜ å°„çš„ç»Ÿè®¡è§„å¾‹**ã€‚

è¾“å…¥å˜é‡ä¸è¾“å‡ºå˜é‡å‡ä¸ºè¿ç»­å˜é‡çš„é¢„æµ‹é—®é¢˜ç§°ä¸º**å›å½’é—®é¢˜**ï¼›
è¾“å‡ºå˜é‡ä¸ºæœ‰é™ä¸ªç¦»æ•£å˜é‡çš„é¢„æµ‹é—®é¢˜ç§°ä¸º**åˆ†ç±»é—®é¢˜**ï¼›
è¾“å…¥å˜é‡ä¸è¾“å‡ºå˜é‡å‡ä¸ºå˜é‡åºåˆ—çš„é¢„æµ‹é—®é¢˜ç§°ä¸º**æ ‡æ³¨é—®é¢˜**(å¯ä»¥ç†è§£ä¸ºç‰¹æ®Šçš„åˆ†ç±»é—®é¢˜)ã€‚

ç›‘ç£å­¦ä¹ çš„æ¨¡å‹å¯ä»¥æ˜¯æ¦‚ç‡æ¨¡å‹æˆ–éæ¦‚ç‡æ¨¡å‹ï¼Œç”±**æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ**$P(Y|X)$æˆ–**å†³ç­–å‡½æ•°ï¼ˆdecision functionï¼‰**$Y=f(X)$è¡¨ç¤ºï¼Œéšå…·ä½“å­¦ä¹ æ–¹æ³•è€Œå®šã€‚å¯¹å…·ä½“çš„è¾“å…¥è¿›è¡Œç›¸åº”çš„è¾“å‡ºé¢„æµ‹æ—¶ï¼Œå†™ä½œ$P(y|x)$æˆ–$Y=f(x)$ã€‚
$$y =\displaystyle\argmax_{y}  P(y|x)$$

**è”åˆæ¦‚ç‡åˆ†å¸ƒ**ï¼š
ç›‘ç£å­¦ä¹ å‡è®¾è¾“å…¥ä¸è¾“å‡ºçš„éšæœºå˜é‡ X å’Œ Y éµå¾ªè”åˆæ¦‚ç‡åˆ†å¸ƒ$P(X,Y)$ã€‚$P(X,Y)$è¡¨ç¤ºåˆ†å¸ƒå‡½æ•°ï¼Œæˆ–åˆ†å¸ƒå¯†åº¦å‡½æ•°ã€‚æ³¨æ„ï¼Œåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œå‡å®šè¿™ä¸€è”åˆæ¦‚ç‡åˆ†å¸ƒå­˜åœ¨ï¼Œä½†å¯¹å­¦ä¹ ç³»ç»Ÿæ¥è¯´ï¼Œè”åˆæ¦‚ç‡åˆ†å¸ƒçš„å…·ä½“å®šä¹‰æ˜¯æœªçŸ¥çš„ã€‚**è®­ç»ƒæ•°æ®ä¸æµ‹è¯•æ•°æ®è¢«çœ‹ä½œæ˜¯ä¾è”åˆæ¦‚ç‡åˆ†å¸ƒ$P(X,Y)$ç‹¬ç«‹åŒåˆ†å¸ƒäº§ç”Ÿçš„**ã€‚
ç»Ÿè®¡å­¦ä¹ å‡è®¾æ•°æ®å­˜åœ¨ä¸€å®šçš„ç»Ÿè®¡è§„å¾‹ï¼Œ$X$å’Œ$Y$å…·æœ‰è”åˆæ¦‚ç‡åˆ†å¸ƒçš„å‡è®¾å°±æ˜¯ç›‘ç£å­¦ä¹ å…³äºæ•°æ®çš„åŸºæœ¬å‡è®¾ã€‚

**éç›‘ç£å­¦ä¹ **ï¼š
éç›‘ç£å­¦ä¹ (unsupervised learning)æ˜¯æŒ‡ä»æ— æ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ é¢„æµ‹æ¨¡å‹çš„æœºå™¨å­¦ä¹ é—®é¢˜ã€‚æœ¬è´¨æ˜¯**å­¦ä¹ æ•°æ®ä¸­çš„ç»Ÿè®¡è§„å¾‹æˆ–æ½œåœ¨ç»“æ„**ã€‚

éç›‘ç£å­¦ä¹ çš„æ¨¡å‹å¯ä»¥è¡¨ç¤ºä¸ºå‡½æ•°$z = g(x)$æˆ–è€…æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ$P(z|x)$ ï¼ˆè¾“å‡º$z$å¯ä»¥æ˜¯**èšç±»**æˆ–è€…**é™ç»´**ï¼‰
$$z =\displaystyle\argmax_{z}  P(z|x)$$
ä»¥åŠ æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ$P(x|z)$ ï¼ˆç”¨æ¥åš**æ¦‚ç‡å¯†åº¦ä¼°è®¡**ï¼Œæ¯”å¦‚ GMM ä¸­$P(x|z)$å±äºé«˜æ–¯åˆ†å¸ƒï¼Œå¦‚æœå‡è®¾çŸ¥é“æ•°æ®æ¥è‡ªå“ªä¸ªé«˜æ–¯åˆ†å¸ƒï¼Œå³çŸ¥é“$z$ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡æ¥ä¼°è®¡ç›¸å…³å‚æ•°ï¼‰ã€‚

**æ¦‚ç‡æ¨¡å‹ï¼ˆprobabilistic modelï¼‰ä¸éæ¦‚ç‡æ¨¡å‹ï¼ˆnon-probabilistic modelï¼‰æˆ–è€…ç¡®å®šæ€§æ¨¡å‹ï¼ˆdeterministic modelï¼‰**ï¼š

æ¦‚ç‡æ¨¡å‹ï¼ˆprobabilistic modelï¼‰- æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ P(y|x)å’Œ éæ¦‚ç‡æ¨¡å‹ï¼ˆnon-probabilistic modelï¼‰ - å‡½æ•° y=f(x)å¯ä»¥**ç›¸äº’è½¬åŒ–**ï¼Œæ¡ä»¶æ¦‚ç‡åˆ†å¸ƒæœ€å¤§åŒ–åå¾—åˆ°å‡½æ•°ï¼Œå‡½æ•°å½’ä¸€åŒ–åå¾—åˆ°æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚æ‰€ä»¥æ¦‚ç‡æ¨¡å‹ä¸éæ¦‚ç‡æ¨¡å‹çš„åŒºåˆ«ä¸åœ¨äºè¾“å…¥è¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»ï¼Œè€Œåœ¨äºæ¨¡å‹çš„å†…éƒ¨ç»“æ„ï¼šæ¦‚ç‡æ¨¡å‹ä¸€å®šå¯ä»¥è¡¨ç¤ºä¸ºè”åˆæ¦‚ç‡åˆ†å¸ƒçš„å½¢å¼ï¼Œè€Œéæ¦‚ç‡æ¨¡å‹åˆ™ä¸ä¸€å®šå­˜åœ¨è¿™æ ·çš„è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚

æ¦‚ç‡æ¨¡å‹çš„ä»£è¡¨æ˜¯**æ¦‚ç‡å›¾æ¨¡å‹ï¼ˆprobabilistic graphical modelï¼‰**$^{å‚è€ƒæ–‡çŒ®[3]}$ï¼Œè”åˆæ¦‚ç‡åˆ†å¸ƒå¯ä»¥æ ¹æ®å›¾çš„ç»“æ„åˆ†è§£ä¸ºå› å­ä¹˜ç§¯çš„å½¢å¼ï¼Œå¯ä»¥ç”¨æœ€åŸºæœ¬çš„åŠ æ³•è§„åˆ™å’Œä¹˜æ³•è§„åˆ™è¿›è¡Œæ¦‚ç‡æ¨ç†ï¼š
$$P(x) = \sum_yP(x,y) \\ P(x,y) = P(x)P(y|x)$$

**å‚æ•°åŒ–æ¨¡å‹ï¼ˆparametric modelï¼‰å’Œéå‚æ•°åŒ–æ¨¡å‹ï¼ˆnon-parametric modelï¼‰**ï¼š

å‚æ•°åŒ–æ¨¡å‹å‡è®¾æ¨¡å‹å‚æ•°çš„ç»´åº¦å›ºå®šï¼Œæ¨¡å‹å¯ä»¥ç”±æœ‰é™ç»´å‚æ•°å®Œå…¨åˆ»ç”»ã€‚(å¦‚ï¼šæ„ŸçŸ¥æœºã€GMM)
éå‚æ•°åŒ–æ¨¡å‹å‡è®¾æ¨¡å‹å‚æ•°çš„å”¯ç‹¬ä¸å›ºå®šæˆ–è€…è¯´æ— ç©·å¤§ï¼Œéšç€è®­ç»ƒæ•°æ®é‡çš„å¢åŠ è€Œä¸æ–­å¢å¤§ã€‚(å¦‚ï¼šå†³ç­–æ ‘ã€æ”¯æŒå‘é‡æœº)

**åœ¨çº¿å­¦ä¹ ï¼ˆonline learningï¼‰å’Œæ‰¹é‡å­¦ä¹ ï¼ˆbatch learningï¼‰**ï¼š

åœ¨çº¿å­¦ä¹ æ¯æ¬¡æ¥å—ä¸€ä¸ªæ ·æœ¬ï¼Œé¢„æµ‹åå­¦ä¹ æ¨¡å‹ï¼Œå¹¶ä¸æ–­é‡å¤è¯¥æ“ä½œã€‚
æ‰¹é‡å­¦ä¹ ä¸€æ¬¡æ¥å—æ‰€æœ‰æ•°æ®ï¼Œå­¦ä¹ æ¨¡å‹ä¹‹åè¿›è¡Œé¢„æµ‹ã€‚

åœ¨çº¿å­¦ä¹ æ¯”æ‰¹é‡å­¦ä¹ æ›´éš¾ï¼Œå› ä¸ºæ¯æ¬¡æ¨¡å‹æ›´æ–°ä¸­å¯åˆ©ç”¨çš„æ•°æ®æœ‰é™ã€‚

**è´å¶æ–¯å­¦ä¹ ï¼ˆBayesian learningï¼‰/ è´å¶æ–¯æ¨ç†ï¼ˆBayesian inferenceï¼‰**ï¼š
$$\mathrm{Bayes \; Rule:} \\ \underbrace{P(X|Y)}_{\mathrm{posterior}} = \frac{\overbrace{P(Y|X)}^{\mathrm{likelihood}}\overbrace{P(X)}^{\mathrm{prior}}}{\underbrace{P(Y)}_{\mathrm{evidence}}}   = \frac{\overbrace{P(Y|X)}^{\mathrm{likelihood}}\overbrace{P(X)}^{\mathrm{prior}}}{\underbrace{\sum_{x}P(Y|X)P(X)}_{\mathrm{evidence}}}$$

**æ ¸æŠ€å·§ï¼ˆkernel trickï¼‰/ æ ¸æ–¹æ³•ï¼ˆkernel methodï¼‰**ï¼š

**æ ¸æ–¹æ³•**æ˜¯ä¸€ç±»æŠŠä½ç»´ç©ºé—´çš„éçº¿æ€§å¯åˆ†é—®é¢˜ï¼Œè½¬åŒ–ä¸ºé«˜ç»´ç©ºé—´çš„çº¿æ€§å¯åˆ†é—®é¢˜çš„æ–¹æ³•ã€‚
**æ ¸æŠ€å·§**æ˜¯ä¸€ç§åˆ©ç”¨æ ¸å‡½æ•°ç›´æ¥è®¡ç®— $\lang \phi(x),\phi(z) \rang$ ï¼Œä»¥é¿å¼€åˆ†åˆ«è®¡ç®— $\phi(x)$ å’Œ $\phi(z)$ ï¼Œä»è€ŒåŠ é€Ÿæ ¸æ–¹æ³•è®¡ç®—çš„æŠ€å·§ã€‚

**æ ¸å‡½æ•°**ï¼šè®¾ $\mathcal X$ æ˜¯è¾“å…¥ç©ºé—´ï¼ˆå³ $x_i \in \mathcal X $ ï¼Œ $\mathcal X$ æ˜¯ $\mathbb R^n$ çš„å­é›†æˆ–ç¦»æ•£é›†åˆ ï¼‰ï¼Œåˆè®¾ $\mathcal H$ ä¸ºç‰¹å¾ç©ºé—´ï¼ˆâ€‹ å¸Œå°”ä¼¯ç‰¹ç©ºé—´$^{é™„åŠ çŸ¥è¯†:å„ç§ç©ºé—´ä»‹ç»}$ï¼‰ï¼Œå¦‚æœå­˜åœ¨ä¸€ä¸ªä» $\mathcal X$ åˆ° $\mathcal H$ çš„æ˜ å°„

$$\phi(x) : \mathcal X \to \mathcal H$$

ä½¿å¾—å¯¹æ‰€æœ‰ $x,z \in \mathcal X$ ï¼Œå‡½æ•° $K(x,z)$ æ»¡è¶³æ¡ä»¶

$$K(x,z) = \phi(x).\phi(z) = \lang \phi(x),\phi(z) \rang$$

åˆ™ç§° $K(x,z)$ ä¸ºæ ¸å‡½æ•°ã€‚å…¶ä¸­ $\phi(x) $ ä¸ºæ˜ å°„å‡½æ•°ï¼Œ $\lang \phi(x),\phi(z) \rang$ ä¸ºå†…ç§¯ã€‚


æ ¸æŠ€å·§çš„æƒ³æ³•æ˜¯ï¼Œåœ¨å­¦ä¹ å’Œé¢„æµ‹ä¸­åªå®šä¹‰æ ¸å‡½æ•° $K(x,z)$ ï¼Œè€Œä¸æ˜¾å¼åœ°å®šä¹‰æ˜ å°„å‡½æ•° $\phi $ã€‚é€šå¸¸ç›´æ¥è®¡ç®—$K(x,z)$æ¯”è¾ƒå®¹æ˜“ï¼Œè€Œé€šè¿‡$\phi(x) $å’Œ$\phi(z) $è®¡ç®—$K(x,z)$å¹¶ä¸å®¹æ˜“ã€‚
> æ³¨æ„ï¼š$\phi $æ˜¯è¾“å…¥ç©ºé—´$\mathbb{R}^n$åˆ°ç‰¹å¾ç©ºé—´$\mathcal H$çš„æ˜ å°„ï¼Œç‰¹å¾ç©ºé—´$\mathcal H$ä¸€èˆ¬æ˜¯é«˜ç»´çš„ï¼Œç”šè‡³æ˜¯æ— ç©·ç»´çš„ã€‚æ‰€ä»¥$\phi$ä¸å¥½è®¡ç®—ï¼Œç”šè‡³ä¼šå¸¦æ¥**ç»´åº¦ç¾éš¾**åˆç§°**ç»´åº¦è¯…å’’ï¼ˆCurse of Dimensionalityï¼‰**$^{é™„åŠ çŸ¥è¯†:ç»´åº¦è¯…å’’}$ã€‚


### é™„åŠ çŸ¥è¯†
#### æ­£åˆ™åŒ–
æ­£åˆ™åŒ–ç¬¦åˆå¥¥å¡å§†å‰ƒåˆ€ï¼ˆOccam's razorï¼‰åŸç†ã€‚

å‚è€ƒï¼š[L1L2æ­£åˆ™åŒ–å’Œå‡¸ä¼˜åŒ–](../å›¾è§£æ•°å­¦/L1L2æ­£åˆ™åŒ–å’Œå‡¸ä¼˜åŒ–.md)

#### æ¨¡å‹é€‰æ‹©

å‚è€ƒï¼š[æ¨¡å‹é€‰æ‹©](../Model-Selection.md)

#### å„ç§ç©ºé—´ä»‹ç»

**çº¿æ€§ç©ºé—´**å°±æ˜¯å®šä¹‰äº†**åŠ æ³•å’Œæ•°ä¹˜**çš„ç©ºé—´(ç©ºé—´é‡Œçš„ä¸€ä¸ªå…ƒç´ å°±å¯ä»¥ç”±å…¶ä»–å…ƒç´ çº¿æ€§è¡¨ç¤º)ã€‚

---

**åº¦é‡ç©ºé—´**å°±æ˜¯å®šä¹‰äº†**è·ç¦»**çš„ç©ºé—´ï¼ˆæ›¼å“ˆé¡¿è·ç¦»ï¼Œæ¬§æ°è·ç¦»ï¼Œé—µå¯å¤«æ–¯åŸºè·ç¦»ï¼Œé©¬æ°è·ç¦»ï¼Œåˆ‡æ¯”é›ªå¤«è·ç¦»ï¼‰ã€‚
å®šä¹‰è·ç¦»æ—¶ï¼Œæœ‰ä¸‰æ¡å…¬ç†å¿…é¡»éµå®ˆï¼š
1. éè´Ÿæ€§ã€åŒä¸€æ€§ï¼š$dist(x_i,x_j) \geq 0$(éè´Ÿæ€§)ï¼Œ$dist(x_i,x_j) = 0$å½“ä¸”ä»…å½“$x_i=x_j$(åŒä¸€æ€§)
2. å¯¹ç§°æ€§ï¼š$dist(x_i,x_j) = dist(x_j,x_i)$
3. ä¸‰è§’ä¸ç­‰å¼(ä¹Ÿå«ç›´é€’æ€§)ï¼š$dist(x_i,x_j) \leq dist(x_i,x_k) + dist(x_k,x_j)$
å¸Œå°”ä¼¯ç‰¹ç©ºé—´(Hilbert)
> æ–‡å­—è§£é‡Šï¼šã€ä¸¤ç‚¹ä¹‹é—´è·ç¦»ä¸ä¸ºè´Ÿï¼›ä¸¤ä¸ªç‚¹åªæœ‰åœ¨ ç©ºé—´ ä¸Šé‡åˆæ‰å¯èƒ½è·ç¦»ä¸ºé›¶ï¼›a åˆ° b çš„è·ç¦»ç­‰äº b åˆ° a çš„è·ç¦»;a åˆ° c çš„è·ç¦»åŠ ä¸Š c åˆ° b çš„è·ç¦»å¤§äºç­‰äº a ç›´æ¥åˆ° b çš„è·ç¦»;ã€‘

---

**èµ‹èŒƒç©ºé—´**å°±æ˜¯å®šä¹‰äº†**èŒƒæ•°**çš„ç©ºé—´ã€‚
xçš„èŒƒæ•°||x||å°±æ˜¯xçš„**é•¿åº¦**ã€‚é‚£ä¹ˆè¿™é‡Œçš„é•¿åº¦å’Œä¸Šä¸€èŠ‚ä¸­è¯´çš„è·ç¦»åˆ°åº•æœ‰ä»€ä¹ˆåŒºåˆ«å‘¢ã€‚**è·ç¦»çš„æ¦‚å¿µæ˜¯é’ˆå¯¹ä¸¤ä¸ªå…ƒç´ æ¥è¯´çš„**ï¼Œä¾‹å¦‚d(x,y)æŒ‡çš„æ˜¯xä¸yä¸¤ä¸ªå…ƒç´ ä¹‹é—´çš„è·ç¦»ï¼Œè€Œ**èŒƒæ•°æ˜¯é’ˆå¯¹ä¸€ä¸ªå…ƒç´ æ¥è¯´çš„**ï¼Œæ¯ä¸€ä¸ªå…ƒç´ éƒ½å¯¹åº”ä¸€ä¸ªèŒƒæ•°ï¼Œå¯ä»¥å°†èŒƒæ•°ç†è§£ä¸ºä¸€ä¸ªå…ƒç´ åˆ°é›¶ç‚¹çš„è·ç¦»ï¼ˆè¿™åªæ˜¯ä¸€ç§ç†è§£ï¼Œå¹¶ä¸æ˜¯å®šä¹‰ï¼‰ï¼Œä¹Ÿå°±æ˜¯å®ƒè‡ªå·±çš„é•¿åº¦ã€‚
å®šä¹‰ï¼š
ç§° æ˜ å°„$||.|| : \mathbb{R}^n \to \mathbb{R}$ä¸º  $\mathbb{R}^n$ ä¸Šçš„èŒƒæ•°ï¼Œå½“ä¸”ä»…å½“ï¼š
1. éè´Ÿæ€§ï¼š $\forall x \in \mathbb{R}^n ,||x|| \geq 0$ ,$||x|| = 0$å½“ä¸”ä»…å½“$x=0$
2. æ•°ä¹˜ï¼š$\forall x \in \mathbb{R}^n ,a \in \mathbb{R}^n, ||ax|| = |a|.||x||$ 
3. ä¸‰è§’ä¸ç­‰å¼: $\forall x,y \in \mathbb{R}^n ,||x+y|| \leq ||x|| + ||y||$ 

å¦‚æœæˆ‘ä»¬å®šä¹‰äº†èŒƒæ•°ï¼Œå¯ä»¥åœ¨è¿™åŸºç¡€ä¸Šå®šä¹‰è·ç¦»ï¼šdist(x,y)=||x-y||ã€‚æ ¹æ®èŒƒæ•°çš„ä¸‰æ¡æ€§è´¨ï¼Œæˆ‘ä»¬å¯ä»¥è¯æ˜æˆ‘ä»¬è¿™æ ·å®šä¹‰çš„è·ç¦»ä¹Ÿæ»¡è¶³è·ç¦»çš„å®šä¹‰ï¼Œèªæ˜çš„ä½ å¯ä»¥è‡ªå·±è¯æ˜ä¸€ä¸‹ï¼ˆå¯¹ç§°æ€§çš„è¯æ˜ï¼Œæä¸€ä¸ª-1å‡ºæ¥ï¼Œä¸€åŠ ç»å¯¹å€¼å°±æ˜¯1äº†ï¼‰ã€‚

ä¹Ÿå°±æ˜¯è¯´èŒƒæ•°å…¶å®æ˜¯ä¸€ä¸ªæ›´åŠ å…·ä½“çš„æ¦‚å¿µï¼Œ**æœ‰äº†èŒƒæ•°ä¸€å®šèƒ½åˆ©ç”¨èŒƒæ•°å®šä¹‰è·ç¦»ï¼Œä½†æ˜¯æœ‰è·ç¦»ä¸èƒ½å®šä¹‰èŒƒæ•°**ã€‚

ä¹Ÿè®¸ä½ ä¼šé—®ï¼Œä½ ä¸æ˜¯è¯´ç†è§£èŒƒæ•°å°±æ˜¯ä¸€ä¸ªå…ƒç´ åˆ°é›¶ç‚¹çš„è·ç¦»å—ï¼Œé‚£å®šä¹‰èŒƒæ•°ä¸º||x||=dist(x,0) ä¸å°±è¡Œäº†å—ã€‚è¿™æ ·çš„è¯ï¼Œå¯¹äºèŒƒæ•°çš„ç¬¬äºŒæ¡æ€§è´¨å°±ä¸ä¸€å®šä¼šæ»¡è¶³ï¼Œ||ax||=dist(ax,0)ï¼Œè€Œdist(ax,0)ä¸ä¸€å®šç­‰äº|a|dist(x,0)ï¼Œå…·ä½“ç­‰ä¸ç­‰äºè¿˜è¦çœ‹ä½ çš„è·ç¦»æ˜¯æ€ä¹ˆå®šä¹‰çš„ã€‚

äº†è§£åˆ°è¿™é‡Œé‚£ä¹ˆä½ ä¼šå‘ç°ï¼š
æ¬§å¼è·ç¦»å¯¹åº”L2èŒƒæ•°
æ›¼å“ˆé¡¿è·ç¦»å¯¹åº”L1èŒƒæ•°

---

**çº¿æ€§èµ‹èŒƒç©ºé—´**å°±æ˜¯å®šä¹‰äº†åŠ æ³•ã€æ•°ä¹˜å’ŒèŒƒæ•°çš„ç©ºé—´ã€‚

---

**å·´æ‹¿èµ«ç©ºé—´**å°±æ˜¯**å®Œå¤‡çš„èµ‹èŒƒçº¿æ€§ç©ºé—´**ã€‚(Banach space)
**å®Œå¤‡çš„ç©ºé—´**çš„å®šä¹‰ï¼šå¦‚æœä¸€ä¸ªç©ºé—´æ˜¯å®Œå¤‡çš„ï¼Œé‚£ä¹ˆè¯¥ç©ºé—´ä¸­çš„ä»»ä½•ä¸€ä¸ªæŸ¯è¥¿åºåˆ—éƒ½æ”¶æ•›åœ¨è¯¥ç©ºé—´ä¹‹å†…ã€‚

é¦–å…ˆæ¥è¯´ä¸€ä¸‹æŸ¯è¥¿åºåˆ—æ˜¯ä»€ä¹ˆï¼ŒæŸ¯è¥¿åºåˆ—å°±æ˜¯éšç€åºæ•°å¢åŠ ï¼Œå€¼ä¹‹é—´çš„è·ç¦»è¶Šæ¥è¶Šå°çš„åºåˆ—ã€‚æ¢ä¸€ç§è¯´æ³•æ˜¯ï¼ŒæŸ¯è¥¿åºåˆ—å¯ä»¥åœ¨å»æ‰æœ‰é™ä¸ªå€¼ä¹‹åï¼Œä½¿ä»»æ„ä¸¤ä¸ªå€¼ä¹‹é—´çš„$\underline{\mathrm{è·ç¦»}}$éƒ½å°äºä»»æ„ç»™å®šæ­£å¸¸æ•°ï¼ˆå…¶å®è¿™å°±æ˜¯å®šä¹‰äº†ä¸€ä¸ªæé™è€Œå·²ï¼‰ã€‚

é‚£ä¹ˆä»»æ„ä¸€ä¸ªæŸ¯è¥¿åºåˆ—éƒ½æ”¶æ•›åœ¨è¯¥ç©ºé—´å†…æ˜¯ä»€ä¹ˆæ„æ€å‘¢ï¼Œä¸¾ä¸ªä¾‹å­ä½ å°±æ˜ç™½äº†ã€‚

è®¾å®šä¹‰åœ¨æœ‰ç†æ•°ç©ºé—´Qä¸Šçš„åºåˆ—ï¼š$x_n = \frac{[\sqrt{2}n]}{n}$ï¼Œå…¶ä¸­[x]è¡¨ç¤ºxå–æ•´æ•°éƒ¨åˆ†ã€‚
å¯¹äºè¿™ä¸ªæ•°åˆ—æ¥è¯´ï¼Œæ¯ä¸€ä¸ªå…ƒç´ çš„åˆ†å­åˆ†æ¯éƒ½æ˜¯æ•´æ•°ï¼Œæ‰€ä»¥æ¯ä¸€ä¸ª$x_n$éƒ½åœ¨æœ‰ç†æ•°ç©ºé—´Qä¸Šï¼Œé‚£è¿™ä¸ªåºåˆ—çš„æé™å‘¢ï¼Œç¨æœ‰å¸¸è¯†çš„äººéƒ½èƒ½çœ‹å‡ºï¼Œè¿™ä¸ªåºåˆ—çš„æé™æ˜¯$\sqrt{2}$ï¼Œè€Œè¿™å¹¶ä¸æ˜¯ä¸€ä¸ªæœ‰ç†æ•°ï¼Œæ‰€ä»¥è¿™ä¸ªæŸ¯è¥¿åºåˆ—çš„æé™ä¸åœ¨è¯¥ç©ºé—´é‡Œé¢ï¼Œä¹Ÿå°±æ˜¯è¯´æœ‰ç†æ•°ç©ºé—´Qæ˜¯ä¸å®Œå¤‡çš„ã€‚

æ‰€ä»¥å®Œå¤‡çš„æ„ä¹‰æˆ‘ä»¬å¯ä»¥è¿™æ ·ç†è§£ï¼Œé‚£å°±æ˜¯**åœ¨ä¸€ä¸ªç©ºé—´ä¸Šæˆ‘ä»¬å®šä¹‰äº†æé™ï¼Œä½†æ˜¯ä¸è®ºä½ æ€ä¹ˆå–æé™ï¼Œå®ƒçš„æé™çš„å€¼éƒ½ä¸ä¼šè·‘å‡ºè¿™ä¸ªç©ºé—´ï¼Œé‚£ä¹ˆè¿™ä¸ªç©ºé—´å°±æ˜¯å®Œå¤‡ç©ºé—´**ã€‚

å¦å¤–ï¼Œä¸çŸ¥é“ä½ æœ‰æ²¡æœ‰å‘ç°ï¼Œä¸Šé¢åœ¨è§£é‡Šä»€ä¹ˆæ˜¯æŸ¯è¥¿åºåˆ—çš„æ—¶å€™ï¼Œæœ‰ä¸€ä¸ªè¯æˆ‘åŠ äº†ä¸‹åˆ’çº¿ï¼Œé‚£å°±æ˜¯è·ç¦»ï¼Œä¹Ÿå°±è¯´è¯´åœ¨å®šä¹‰å®Œå¤‡ç©ºé—´ä¹‹å‰ï¼Œè¦å…ˆæœ‰è·ç¦»çš„æ¦‚å¿µã€‚æ‰€ä»¥**å®Œå¤‡ç©ºé—´ï¼Œå…¶å®ä¹Ÿæ˜¯å®Œå¤‡åº¦é‡ç©ºé—´**ã€‚

æ‰€ä»¥ï¼Œå·´æ‹¿èµ«ç©ºé—´æ»¡è¶³å‡ æ¡ç‰¹æ€§å‘¢ï¼šè·ç¦»ã€èŒƒæ•°ã€å®Œå¤‡ã€‚

---

**å†…ç§¯ç©ºé—´**å°±æ˜¯å®šä¹‰äº†å†…ç§¯çš„ç©ºé—´ã€‚[Inner product space](https://en.jinzhao.wiki/wiki/Inner_product_space)
æœ‰æ—¶ä¹Ÿç§°å‡†å¸Œå°”ä¼¯ç‰¹ç©ºé—´ã€‚
å†…ç§¯å°±æ˜¯æˆ‘ä»¬æ‰€è¯´çš„ç‚¹ä¹˜ã€æ ‡ç§¯ï¼Œå®ƒçš„å®šä¹‰æ–¹å¼ä¹Ÿä¸æ˜¯å”¯ä¸€çš„ï¼Œä½†å¦‚åŒè·ç¦»èŒƒæ•°çš„å®šä¹‰ä¸€æ ·ï¼Œå†…ç§¯çš„å®šä¹‰ä¹Ÿè¦æ»¡è¶³æŸäº›æ¡ä»¶ï¼Œä¸èƒ½éšä¾¿å®šä¹‰ã€‚

å®šä¹‰æ˜ å°„$\lang .,. \rang : V \times V \to \mathbb{F}$, å…¶ä¸­$V$æ˜¯å‘é‡ï¼Œ$\mathbb{F}$æ˜¯æ ‡é‡
æœ‰$x,y,z \in V ,s \in \mathbb{F}$ï¼Œé‚£ä¹ˆå†…ç§¯æ»¡è¶³
1. ç¬¬ä¸€ä¸ªå‚æ•°ä¸­çš„çº¿æ€§:
$$\lang sx,y \rang = s\lang x,y \rang \\ \lang x+y,z \rang = \lang x,z \rang + \lang y,z \rang \\ \lang 0,x \rang = 0$$

2. å…±è½­å¯¹ç§°:$\lang x,y \rang = \overline{\lang y,x \rang }$

3. æ­£å®šæ€§:$\lang x,x \rang > 0 \quad\mathrm{if}\; x \neq 0$

4. æ­£åŠå®šæ€§æˆ–éè´Ÿå®šæ€§:$\forall{x}, \lang x,x \rang \geq 0 $

5. ç¡®å®šæ€§ï¼š$\lang x,x \rang = 0 å¿…ç„¶æœ‰ x=0$

3ï¼Œ4ï¼Œ5å¯ä»¥è·Ÿä¸Šé¢å®šä¹‰èŒƒæ•°å’Œè·ç¦»ä¸€æ ·å†™æˆä¸€ä¸ª

ä¾‹å­-æ¬§å‡ é‡Œå¾—å‘é‡ç©ºé—´:
$ x,y \in \mathbb{R}^n , \lang x,y \rang = x^Ty=\sum_{i=1}^n{x_iy_i}$


**åªæœ‰å®šä¹‰äº†å†…ç§¯ï¼Œæ‰ä¼šæœ‰å¤¹è§’çš„æ¦‚å¿µï¼Œæ‰ä¼šæœ‰æ­£äº¤çš„æ¦‚å¿µï¼Œå¦å¤–å†…ç§¯ä¹Ÿå¯ä»¥å®šä¹‰èŒƒæ•°ï¼Œä¹Ÿå°±æ˜¯è¯´å†…ç§¯æ˜¯æ¯”èŒƒæ•°æ›´å…·ä½“çš„ä¸€ä¸ªæ¦‚å¿µã€‚**

---

**æ¬§å¼ç©ºé—´**å°±æ˜¯å®šä¹‰äº†å†…ç§¯çš„æœ‰é™ç»´å®çº¿æ€§ç©ºé—´ã€‚

---

**å¸Œå°”ä¼¯ç‰¹ç©ºé—´**å°±æ˜¯å®Œå¤‡çš„å†…ç§¯ç©ºé—´ã€‚(Hilbert space)
å¸Œå°”ä¼¯ç‰¹ç©ºé—´ä¸­çš„å…ƒç´ ä¸€èˆ¬æ˜¯å‡½æ•°ï¼Œå› ä¸ºä¸€ä¸ªå‡½æ•°å¯ä»¥è§†ä¸ºä¸€ä¸ªæ— ç©·ç»´çš„å‘é‡ã€‚


```mermaid
graph LR;
    LS(("Linear Space"))-->NLS(("Normed Linear Space"));
    NLS-->BS(("Banach Space"))
    NLS-->IPS(("Inner Product Space"))
    IPS-->HS(("Hilbert Space"))
    IPS-->ES(("Euclid Space"))
```

![](https://pic2.zhimg.com/80/v2-be26b2ba1df2edc9636647a28b22238d_720w.jpg?source=1940ef5c)


å‚è€ƒï¼š[ä¸€ç‰‡æ–‡ç« å¸¦ä½ ç†è§£å†ç”Ÿæ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´ï¼ˆRKHSï¼‰ä»¥åŠå„ç§ç©ºé—´](https://blog.csdn.net/ChangHengyi/article/details/80577318)

#### ç»´åº¦è¯…å’’
ç»´åº¦è¯…å’’é€šå¸¸æ˜¯æŒ‡åœ¨æ¶‰åŠåˆ°å‘é‡çš„è®¡ç®—çš„é—®é¢˜ä¸­ï¼Œéšç€ç»´æ•°çš„å¢åŠ ï¼Œè®¡ç®—é‡å‘ˆæŒ‡æ•°å€å¢é•¿çš„ä¸€ç§ç°è±¡ã€‚é«˜ç»´åº¦æœ‰æ›´å¤§çš„ç‰¹å¾ç©ºé—´ï¼Œéœ€è¦æ›´å¤šçš„æ•°æ®æ‰å¯ä»¥è¿›è¡Œè¾ƒå‡†ç¡®çš„ä¼°è®¡ã€‚
> è‹¥ç‰¹å¾æ˜¯äºŒå€¼çš„ï¼Œåˆ™æ¯å¢åŠ ä¸€ä¸ªç‰¹å¾ï¼Œæ‰€éœ€æ•°æ®é‡éƒ½åœ¨ä»¥2çš„æŒ‡æ•°çº§è¿›è¡Œå¢é•¿ï¼Œæ›´ä½•å†µå¾ˆå¤šç‰¹å¾ä¸åªæ˜¯äºŒå€¼çš„ã€‚

å‡ ä½•è§’åº¦1ï¼š

<svg width="52" height="52" xmlns="http://www.w3.org/2000/svg">
 <!-- Created with Method Draw - http://github.com/duopixel/Method-Draw/ -->
 <g>
  <title>background</title>
  <rect fill="#fff" id="canvas_background" height="54" width="54" y="-1" x="-1"/>
  <g display="none" overflow="visible" y="0" x="0" height="100%" width="100%" id="canvasGrid">
   <rect fill="url(#gridpattern)" stroke-width="0" y="0" x="0" height="100%" width="100%"/>
  </g>
 </g>
 <g>
  <title>Layer 1</title>
  <rect stroke="#000" id="svg_1" height="50" width="50" y="1.134891" x="1.227186" stroke-width="1.5" fill="#fff"/>
  <ellipse stroke="#000" ry="25" rx="25" id="svg_2" cy="26.316708" cx="25.727185" fill-opacity="null" stroke-opacity="null" stroke-width="1.5" fill="#fff"/>
  <line stroke-linecap="null" stroke-linejoin="null" id="svg_3" y2="26.363651" x2="49.090879" y1="26.363651" x1="23.636325" fill-opacity="null" stroke-opacity="null" stroke-width="1.5" stroke="#000" fill="none"/>
  <text stroke="#000" transform="matrix(0.8454890517551235,0,0,0.38060957631270753,66.36433546231878,120.48066499237646) " xml:space="preserve" text-anchor="start" font-family="Helvetica, Arial, sans-serif" font-size="24" id="svg_4" y="-262.016546" x="-56.089448" fill-opacity="null" stroke-opacity="null" stroke-width="0" fill="#000000">0.5</text>
 </g>
</svg>

ä¸Šå›¾è¡¨ç¤ºä¸€ä¸ªå¤šç»´ç©ºé—´ï¼ˆä»¥äºŒç»´ä¸ºä¾‹ï¼‰ï¼Œè®¾æ­£æ–¹å½¢è¾¹é•¿ä¸º1ï¼Œåˆ™å…¶å†…åˆ‡åœ†åŠå¾„ä¸º$r=0.5$ï¼Œåˆ™æ­£æ–¹å½¢é¢ç§¯ä¸º1ï¼Œå†…åˆ‡åœ†é¢ç§¯ä¸º$\pi(0.5)^2$ ã€‚è‹¥å°†æ­¤å˜ä¸ºä¸‰ç»´æƒ…å†µä¸‹ï¼Œæ­£æ–¹ä½“ä½“ç§¯ä¸º1ï¼Œå†…åˆ‡çƒä½“ç§¯ä¸º$\frac{4}{3}\pi(0.5)^3$ã€‚

å› æ­¤çƒä½“çš„ä½“ç§¯å¯ä»¥è¡¨ç¤ºä¸º$V(d) = \frac{\pi^{d/2}}{\varGamma(\frac{d}{2}+1)}0.5^d = k(0.5)^d$(dä¸ºç»´åº¦),åˆ™ $\lim_{d \to \infty}k(0.5)^d = 0$ï¼Œå…¶å†…åˆ‡è¶…çƒä½“çš„ä½“ç§¯ä¸º0ã€‚ç”±æ­¤å¯çŸ¥ï¼Œ**é«˜ç»´æƒ…å†µä¸‹ï¼Œæ•°æ®å¤§éƒ½åˆ†å¸ƒåœ¨å››è§’ï¼ˆæ­£æ–¹å½¢å†…ï¼Œå†…åˆ‡åœ†å¤–ï¼‰**ï¼Œç¨€ç–æ€§å¤ªå¤§ï¼Œä¸å¥½åˆ†ç±»ã€‚
> ç»´åº¦è¶Šå¤§ï¼Œè¶…çƒä½“ä½“ç§¯è¶Šå°ã€‚è¯´æ˜è½åœ¨è¶…çƒä½“å†…çš„æ ·æœ¬è¶Šå°‘ï¼Œå› ä¸ºè¶…çƒä½“æ˜¯è¶…ç«‹æ–¹ä½“çš„å†…åˆ‡çƒã€‚ä¸åœ¨çƒå†…,é‚£åªèƒ½åœ¨è§’è½ï¼

å‡ ä½•è§’åº¦2ï¼š

<svg width="52" height="52" xmlns="http://www.w3.org/2000/svg">
 <!-- Created with Method Draw - http://github.com/duopixel/Method-Draw/ -->
 <g>
  <title>background</title>
  <rect fill="#fff" id="canvas_background" height="54" width="54" y="-1" x="-1"/>
  <g display="none" overflow="visible" y="0" x="0" height="100%" width="100%" id="canvasGrid">
   <rect fill="url(#gridpattern)" stroke-width="0" y="0" x="0" height="100%" width="100%"/>
  </g>
 </g>
 <g>
  <title>Layer 1</title>
  <ellipse stroke="#000" ry="25" rx="25" id="svg_5" cy="25" cx="25" fill-opacity="null" stroke-opacity="null" stroke-width="1.5" fill="#fff"/>
  <ellipse id="svg_6" cy="24.593763" cx="34.636353" fill-opacity="null" stroke-opacity="null" stroke-width="1.5" stroke="#000" fill="#fff"/>
  <ellipse ry="20" rx="20" id="svg_7" cy="25" cx="25" fill-opacity="null" stroke-opacity="null" stroke-width="1.5" stroke="#000" fill="#fff"/>
 </g>
</svg>

ä¸Šå›¾ä¹Ÿè¡¨ç¤ºä¸€ä¸ªå¤šç»´ç©ºé—´ï¼ˆä»¥äºŒç»´ä¸ºä¾‹ï¼‰ï¼Œåˆ™å…¶ä¸­å›¾å½¢çš„ä½“ç§¯æœ‰å¦‚ä¸‹å…³ç³»ï¼šå¤–åœ†åŠå¾„$r=1$ï¼Œå†…åœ†åŠå¾„ä¸º$râˆ’\varepsilon$ ã€‚åŒæ ·åœ¨é«˜ç»´æƒ…å†µä¸‹ï¼Œå¤–åœ†ä½“ç§¯ä¸º$V_{å¤–åœ†} = k.1^d = k$ï¼Œä¸­é—´çš„åœ†ç¯ä½“ç§¯ä¸º$V_{åœ†ç¯} = k - k(1-\varepsilon)^d$ï¼Œåˆ™ï¼š
$$\lim_{d \to \infty}\frac{V_{åœ†ç¯}}{V_{å¤–åœ†}} = \lim_{d \to \infty}\frac{ k - k(1-\varepsilon)^d}{k} = \lim_{d \to \infty}(1-(1-\varepsilon)^d) = 1$$

> é«˜ç»´æƒ…å†µä¸‹ï¼Œæ— è®º$\varepsilon$å¤šå°ï¼Œåªè¦dè¶³å¤Ÿå¤§ï¼Œåœ†ç¯å‡ ä¹å æ®äº†æ•´ä¸ªå¤–åœ†ï¼Œå†…åœ†ä½“ç§¯è¶‹å‘äº0ï¼Œå¯¼è‡´æ•°æ®**ç¨€ç–**ã€‚

å‚è€ƒï¼š
[The Curse of Dimensionality in classification](https://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/)
[æœºå™¨å­¦ä¹ -ç™½æ¿æ¨å¯¼ç³»åˆ—(äº”)-é™ç»´ï¼ˆDimensionality Reductionï¼‰](https://www.bilibili.com/video/BV1vW411S7tH)

#### ä¸ç­‰å¼(Inequality)

[æ‰€æœ‰ä¸ç­‰å¼](https://en.jinzhao.wiki/wiki/Category:Inequalities) ä»¥åŠ[æ‰€æœ‰æ¦‚ç‡ï¼ˆProbabilisticï¼‰ä¸ç­‰å¼](https://en.jinzhao.wiki/wiki/Category:Probabilistic_inequalities)

- **[ç»å¯¹å€¼ä¸ç­‰å¼](https://chi.jinzhao.wiki/wiki/%E7%BB%9D%E5%AF%B9%E5%80%BC%E4%B8%8D%E7%AD%89%E5%BC%8F) - Absolute value inequality**

- **å¹‚å¹³å‡å€¼ä¸ç­‰å¼- [Power-Mean Inequality](https://artofproblemsolving.com/wiki/index.php/Power_Mean_Inequality)**

- **[ä¸‰è§’å½¢å†…è§’çš„åµŒå…¥ä¸ç­‰å¼](https://chi.jinzhao.wiki/wiki/%E4%B8%89%E8%A7%92%E5%BD%A2%E5%86%85%E8%A7%92%E7%9A%84%E5%B5%8C%E5%85%A5%E4%B8%8D%E7%AD%89%E5%BC%8F) - æœ‰æ—¶ä¹Ÿè¢«ç§°ä¸ºWolstenholmeä¸ç­‰å¼**

- **ä¼¯åŠªåˆ©ä¸ç­‰å¼ - [Bernoulli's inequality](https://en.jinzhao.wiki/wiki/Bernoulli%27s_inequality)**
- **æ’åºä¸ç­‰å¼ - [Rearrangement inequality](https://en.jinzhao.wiki/wiki/Rearrangement_inequality)**
- **å‡å€¼ä¸ç­‰å¼ - [Inequality of arithmetic and geometric means](https://en.jinzhao.wiki/wiki/Inequality_of_arithmetic_and_geometric_means)**

- **èˆ’å°”ä¸ç­‰å¼ - [Schur's inequality](https://en.jinzhao.wiki/wiki/Schur%27s_inequality)**


- **é—µå¯å¤«æ–¯åŸº (Minkowski) ä¸ç­‰å¼ - [Minkowski inequality](https://en.jinzhao.wiki/wiki/Minkowski_inequality)**

##### æ¦‚ç‡ä¸ç­‰å¼ Probabilistic inequalities

- **æŸ¯è¥¿-æ–½ç“¦èŒ¨ (Cauchyâ€“Schwarz) ä¸ç­‰å¼ - [Cauchyâ€“Schwarz inequality](https://en.jinzhao.wiki/wiki/Cauchy%E2%80%93Schwarz_inequality)**
    $$[\sum_{i=1}^{n}{a_ib_i}]^2  \leq [\sum_{i=1}^{n}a_i^2].[\sum_{i=1}^{n}b_i^2] ç­‰å¼æˆç«‹ï¼šb_i=ka_i \\ å‘é‡å½¢å¼ï¼š|\braket{u,v}| \leq ||u||.||v|| \\ æ¦‚ç‡ä¸­ï¼š|E(XY)|^2 \leq E(X^2)E(Y^2)$$
    è¯æ˜ï¼š
    $$\vec{A} = (a_1,...,a_n),  \vec{B} = (b_1,...,b_n) \\ \vec{A}.\vec{B} = (a_1b_1,...,a_nb_n) = |\vec{A}|.|\vec{B}|\cos\theta \leq |\vec{A}|.|\vec{B}| = \sqrt{a_1^2+...+a_n^2}.\sqrt{b_1^2+...+b_n^2}$$
    åº”ç”¨:
    1. è¯æ˜covariance inequalityï¼š$Var(Y) \geq \frac{Cov(Y,X)^2}{Var(X)}$,æœ‰$\braket{X,Y} := E(XY)$
    $$|Cov(Y,X)|^2 = |E((X-\mu)(Y-v))|^2 = |\braket{X-\mu,Y-v}|^2 \\ \leq \braket{X-\mu,X-\mu}\braket{Y-v,Y-v} = E((X-\mu)^2)E((Y-v)^2) = Var(X)Var(Y)$$

- **èµ«å°”å¾· (Holder) ä¸ç­‰å¼ - [HÃ¶lder's inequality](https://en.jinzhao.wiki/wiki/H%C3%B6lder%27s_inequality)**

- **ç´ç”Ÿ (Jensen) ä¸ç­‰å¼ - [Jensen's inequality](https://en.jinzhao.wiki/wiki/Jensen%27s_inequality)**
    $$f(tx_1 +(1-t)x_2) \leq tf(x_1) + (1-t)f(x_2), \text{f is convex function} \\ æ¨å¹¿ï¼šf(a_1x_1 +...+ a_nx_n) \leq a_1f(x_1) +...+ a_nf(x_n), a_1+...+a_n = 1 , a_i \geq 0 \\ or: f(\sum_{i=1}^n{a_ix_i}) \leq \sum_{i=1}^n{a_if(x_i)} , \sum_{i=1}^n{a_i} = 1, a_i \geq 0$$
    
    æ¦‚ç‡ä¸­ï¼šå¦‚æœ$X$æ˜¯éšæœºå˜é‡ï¼Œè€Œ$\varphi$æ˜¯å‡¸å‡½æ•°ï¼Œåˆ™:$\varphi(E[X]) \leq E[\varphi(X)]$,ä¸ç­‰å¼ä¸¤è¾¹çš„å·®ï¼Œ$ E[\varphi(X)] - \varphi(E[X]) $ç§°ä¸ºJensen gap(é—´éš™)ï¼›
    åº”ç”¨ï¼š
    1. EMç®—æ³•ä¸­æœ‰ç”¨åˆ°(logå‡½æ•°æ˜¯å‡¹å‡½æ•°æ­£å¥½ä¸å‡¸å‡½æ•°ç›¸å);
    2. è¯æ˜KLæ•£åº¦>=0;


- **é©¬å°”å¯å¤«ä¸ç­‰å¼ - [Markov's inequality](https://en.jinzhao.wiki/wiki/Markov%27s_inequality)**
    $$P(X \geq a) \leq \frac{E(X)}{a}$$
    å…¶ä¸­$X$ä¸ºéè´Ÿéšæœºå˜é‡ï¼Œ$\forall a>0$
    åº”ç”¨ï¼š
    1. ç”¨äºä¼°è®¡ä¸€ä¸ªæ¦‚ç‡çš„ä¸Šç•Œï¼Œæ¯”å¦‚å‡è®¾ä½ æ‰€åœ¨å…¬å¸çš„äººå‡å·¥èµ„æ˜¯1ä¸‡ï¼Œé‚£ä¹ˆéšæœºé€‰ä¸€ä¸ªä½ å¸å‘˜å·¥ï¼Œå…¶å·¥èµ„è¶…è¿‡10ä¸‡çš„æ¦‚ç‡ï¼Œä¸ä¼šè¶…è¿‡1/10ï¼›
    2. ç”¨äºå…¶ä»–æ¦‚ç‡ä¸ç­‰å¼çš„è¯æ˜ï¼Œæ¯”å¦‚éœå¤«ä¸ä¸ç­‰å¼ï¼›

- **åˆ‡æ¯”é›ªå¤« (Chebyshev) ä¸ç­‰å¼ - [Chebyshev's inequality](https://en.jinzhao.wiki/wiki/Chebyshev%27s_inequality)**
     $$P\{|X-\mu| \geq k\} \leq \frac{\sigma^2}{k^2}$$
    å…¶ä¸­$X$ä¸ºéšæœºå˜é‡ï¼Œ$\forall k>0$, $\mu$ä¸ºå‡å€¼ï¼Œ$\sigma^2$ä¸ºæ–¹å·®
    ï¼ˆè¯æ˜å¯ä»¥åˆ©ç”¨é©¬å°”å¯å¤«ä¸ç­‰å¼ï¼Œè§æ¦‚ç‡è®ºåŸºç¡€æ•™ç¨‹313é¡µï¼‰

- **éœå¤«ä¸ä¸ç­‰å¼ - [Hoeffding's inequality](https://en.jinzhao.wiki/wiki/Hoeffding%27s_inequality)**

å‚è€ƒï¼š[åˆç­‰æ•°å­¦å­¦ä¹ ç¬”è®°](https://github.com/zhcosin/elementary-math/blob/master/elementary-math-note.pdf)


### å‚è€ƒæ–‡çŒ®

[1] Hastie T,Tibshirani R,Friedman J. [The Elements of Statistical Learning: DataMining,Inference,and Prediction](http://www.web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12_toc.pdf). Springer. 2001ï¼ˆä¸­è¯‘æœ¬ï¼šç»Ÿè®¡å­¦ä¹ åŸºç¡€â€”â€”æ•°æ®æŒ–æ˜ã€æ¨ç†ä¸é¢„æµ‹ã€‚èŒƒæ˜ï¼ŒæŸ´ç‰æ¢…ï¼Œæ˜çº¢è‹±ç­‰è¯‘ã€‚åŒ—äº¬ï¼šç”µå­å·¥ä¸šå‡ºç‰ˆç¤¾ï¼Œ2004ï¼‰

[2] Bishop M. [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf). Springer,2006

[3] [Probabilistic Graphical Models: Principles and Techniques](https://djsaunde.github.io/read/books/pdfs/probabilistic%20graphical%20models.pdf) by Daphne Koller, Nir Friedman from The MIT Press

[4] [Deep Learning](https://raw.fastgit.org/Zhenye-Na/machine-learning-uiuc/master/docs/Deep%20Learning.pdf) (Ian Goodfellow, Yoshua Bengio, Aaron Courville)

[5] Tom M Michelle. [Machine Learning](https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html). McGraw-Hill Companies,Inc. 1997ï¼ˆä¸­è¯‘æœ¬ï¼šæœºå™¨å­¦ä¹ ã€‚åŒ—äº¬ï¼šæœºæ¢°å·¥ä¸šå‡ºç‰ˆç¤¾ï¼Œ2003ï¼‰

[6] [Bayesian Reasoning and Machine Learning by David Barber 2007â€“2020](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/200620.pdf) ,[other version](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/)

[7] [Reinforcement Learning:An Introduction (second edition 2020) by Richard S. Sutton and Andrew G. Barto](http://incompleteideas.net/book/RLbook2020trimmed.pdf) ,[other version](http://incompleteideas.net/book/)

[8] å‘¨å¿—åï¼Œ[æœºå™¨å­¦ä¹ ](https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E5%BF%97%E5%8D%8E.pdf)ï¼Œæ¸…åå¤§å­¦å‡ºç‰ˆç¤¾ ([æ‰‹æ¨ç¬”è®°](https://github.com/Sophia-11/Machine-Learning-Notes) ä»¥åŠ [å…¬å¼æ¨å¯¼è§£æ](https://github.com/datawhalechina/pumpkin-book))

[9] [Lecture Notes in MACHINE LEARNING](https://news.vidyaacademy.ac.in/wp-content/uploads/2018/10/NotesOnMachineLearningForBTech-1.pdf) Dr V N Krishnachandran

## ç¬¬ 2 ç«  æ„ŸçŸ¥æœº
